{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"ACCELERATE_DISABLE_RICH\"] = \"1\"\n",
    "import sys\n",
    "import torch as t\n",
    "from pathlib import Path\n",
    "\n",
    "# Make sure exercises are in the path\n",
    "# chapter = r\"chapter1_transformers\"\n",
    "# exercises_dir = Path(f\"{os.getcwd().split(chapter)[0]}/{chapter}/exercises\").resolve()\n",
    "# section_dir = exercises_dir / \"monthly_algorithmic_problems\" / \"october23_sorted_list\"\n",
    "# if str(exercises_dir) not in sys.path: sys.path.append(str(exercises_dir))\n",
    "\n",
    "from dataset import SortedListDataset\n",
    "from model import create_model\n",
    "from plotly_utils_file import hist, bar, imshow\n",
    "\n",
    "device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SortedListDataset(size=1, list_len=5, max_value=10, seed=42)\n",
    "\n",
    "print(dataset[0].tolist())\n",
    "print(dataset.str_toks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"sorted_list_model.pt\"\n",
    "\n",
    "model = create_model(\n",
    "    list_len=10,\n",
    "    max_value=50,\n",
    "    seed=0,\n",
    "    d_model=96,\n",
    "    d_head=48,\n",
    "    n_layers=1,\n",
    "    n_heads=2,\n",
    "    normalization_type=\"LN\",\n",
    "    d_mlp=None,\n",
    ")\n",
    "\n",
    "state_dict = t.load(filename)\n",
    "\n",
    "state_dict = model.center_writing_weights(t.load(filename))\n",
    "state_dict = model.center_unembed(state_dict)\n",
    "state_dict = model.fold_layer_norm(state_dict)\n",
    "state_dict = model.fold_value_biases(state_dict)\n",
    "model.load_state_dict(state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ln_final weight: \", model.ln_final.w)\n",
    "print(\"\\nln_final, bias: \", model.ln_final.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500\n",
    "dataset = SortedListDataset(size=N, list_len=10, max_value=50, seed=43)\n",
    "\n",
    "logits, cache = model.run_with_cache(dataset.toks)\n",
    "logits: t.Tensor = logits[:, dataset.list_len : -1, :]\n",
    "\n",
    "targets = dataset.toks[:, dataset.list_len + 1 :]\n",
    "\n",
    "logprobs = logits.log_softmax(-1)  # [batch seq_len vocab_out]\n",
    "probs = logprobs.softmax(-1)\n",
    "\n",
    "batch_size, seq_len = dataset.toks.shape\n",
    "logprobs_correct = eindex(logprobs, targets, \"batch seq [batch seq]\")\n",
    "probs_correct = eindex(probs, targets, \"batch seq [batch seq]\")\n",
    "\n",
    "avg_cross_entropy_loss = -logprobs_correct.mean().item()\n",
    "\n",
    "print(f\"Average cross entropy loss: {avg_cross_entropy_loss:.3f}\")\n",
    "print(f\"Mean probability on correct label: {probs_correct.mean():.3f}\")\n",
    "print(f\"Median probability on correct label: {probs_correct.median():.3f}\")\n",
    "print(f\"Min probability on correct label: {probs_correct.min():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(dataset: SortedListDataset, batch_idx: int):\n",
    "    logits: Tensor = model(dataset.toks)[:, dataset.list_len : -1, :]\n",
    "    logprobs = logits.log_softmax(-1)  # [batch seq_len vocab_out]\n",
    "    probs = logprobs.softmax(-1)\n",
    "\n",
    "    str_targets = dataset.str_toks[batch_idx][dataset.list_len + 1 : dataset.seq_len]\n",
    "\n",
    "    imshow(\n",
    "        probs[batch_idx].T,\n",
    "        y=dataset.vocab,\n",
    "        x=[\n",
    "            f\"{dataset.str_toks[batch_idx][j]}<br><sub>({j})</sub>\"\n",
    "            for j in range(dataset.list_len + 1, dataset.seq_len)\n",
    "        ],\n",
    "        labels={\"x\": \"Token\", \"y\": \"Vocab\"},\n",
    "        xaxis_tickangle=0,\n",
    "        title=f\"Sample model probabilities:<br>Unsorted = ({','.join(dataset.str_toks[batch_idx][:dataset.list_len])})\",\n",
    "        text=[\n",
    "            [\"ã€‡\" if (str_tok == target) else \"\" for target in str_targets]\n",
    "            for str_tok in dataset.vocab\n",
    "        ],\n",
    "        width=400,\n",
    "        height=1000,\n",
    "    )\n",
    "\n",
    "\n",
    "show(dataset, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
